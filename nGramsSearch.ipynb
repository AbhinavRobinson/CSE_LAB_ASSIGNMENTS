{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nGramsSearch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavRobinson/CS_WORKHORSE/blob/master/nGramsSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMWRmbQzNBzt",
        "colab_type": "code",
        "outputId": "3f167bdc-1389-4c7a-9729-481b84373280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "from __future__ import absolute_import , print_function, unicode_literals\n",
        "from collections import Counter\n",
        "import operator\n",
        "from pprint import pprint\n",
        "import re\n",
        "\n",
        "# This Algorithm works for sentences starting with any letter\n",
        "#           ie,   \" I am ...\" or even for \" Apple is ... \" etc.\n",
        "# Function obtains the head of list containing first element in sentence\n",
        "# we generate a user key type trigger_muff_1n\n",
        "_usepythontype_ = \"h1na\"\n",
        "\n",
        "# This function gets the ngrams only for the head of the sentence\n",
        "def get_head_list(n_grams_list,key):\n",
        "  if key and True:\n",
        "    index, s_index = 0,0\n",
        "    n_list = []\n",
        "    for items in n_grams_list:\n",
        "      # We compare the first item in items to the first of each sentence\n",
        "      if items[0] == \"I\" :#n_grams_list[0][0]:\n",
        "        n_list.append(n_grams_list[index].lower())\n",
        "        # s_index+=1\n",
        "      index+=1\n",
        "    return n_list\n",
        "\n",
        "def n_grams(sen,n = -1):\n",
        "  # Clean the input sentences\n",
        "  word_list = re.sub(r'[^a-zA-Z0-9\\S]', ' ', sen)\n",
        "  # Break sentence in the token, remove empty tokens\n",
        "  tokens = [token for token in word_list.split(\" \") if token != \"\"]\n",
        "  # zips the word groups\n",
        "  if n != -1:\n",
        "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
        "  else:\n",
        "    ngrams = zip(*[tokens[i:] for i in range(20)])\n",
        "    temp = [[]]*10\n",
        "    index = 0\n",
        "    for letter in [\" \".join(ngram) for ngram in ngrams][index]:\n",
        "      if letter == '.':\n",
        "        index+=1\n",
        "        continue\n",
        "      temp[index].append(letter)\n",
        "    temp = [\"\".join(temp[0]) for token in [temp[index] for index in range(len(temp))]] \n",
        "    pprint(temp)\n",
        "#     pprint([\" \".join(ngram) for ngram in ngrams])\n",
        "  # returns after joining the ngrams\n",
        "  return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "# Now we will write a prediction function\n",
        "# def predict(word = 'i'):\n",
        "#   if(word.lower()=='i'):\n",
        "#     for phrases in two_grams:\n",
        "\n",
        "\n",
        "\n",
        "with open(\"sample.txt\") as file:\n",
        "  # START POINT \n",
        "  data = file.read()\n",
        "  # We have seperated the words and the non alphanumericals\n",
        "  key = \"a6\" + _usepythontype_ + 'v'\n",
        "  # We also create 2,3,4-grams\n",
        "  # makes the ngrams\n",
        "  two_grams = get_head_list(n_grams(data,2),key)\n",
        "  three_grams = get_head_list(n_grams(data,3),key)\n",
        "  four_grams =  get_head_list(n_grams(data,4),key)\n",
        "  full_grams = get_head_list(n_grams(data),key)\n",
        "  # Now we will count up the list and convert it to a dictionary and sort it\n",
        "  two_grams   = sorted({x:two_grams.count(x) for x in two_grams}.items(), \n",
        "                      key=operator.itemgetter(1), \n",
        "                      reverse = True)\n",
        "  three_grams = sorted({x:three_grams.count(x) for x in three_grams}.items(), \n",
        "                      key=operator.itemgetter(1), \n",
        "                      reverse = True)\n",
        "  four_grams  = sorted({x:four_grams.count(x) for x in four_grams}.items(), \n",
        "                      key=operator.itemgetter(1), \n",
        "                      reverse = True)\n",
        "  full_grams  = sorted({x:four_grams.count(x) for x in full_grams}.items(), \n",
        "                      key=operator.itemgetter(1), \n",
        "                      reverse = True)\n",
        "  # Now lets take input from user\n",
        "  # while True:\n",
        "  #   user_str = input()\n",
        "  #   if user_str == \"end\":\n",
        "  #     break\n",
        "  #   else:"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of',\n",
            " 'I love the world and the things in it I love the way cheetah runs I am a man '\n",
            " 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dy5fr97iTSd",
        "colab_type": "code",
        "outputId": "b657af2b-51c1-48b5-e7b7-7d3cd0c6089e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "\n",
        "# Just bug testing â€ŽðŸ¤”\n",
        "# two_grams, three_grams, four_grams\n",
        "full_grams"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i love the world and the things in it. i', 0),\n",
              " ('i love the way cheetah runs. i am a man', 0),\n",
              " ('i am a man of honor. i will be a', 0),\n",
              " ('i will be a rich guy. i am a teenager', 0),\n",
              " ('i am a teenager so i am a rebel. i', 0),\n",
              " ('i am a rebel. i am an iconoclast and a', 0),\n",
              " ('i am an iconoclast and a fighter i believe in', 0),\n",
              " ('i believe in education. i love everything. i watch a', 0),\n",
              " ('i love everything. i watch a movie every day. i', 0),\n",
              " ('i watch a movie every day. i hate pollution. i', 0),\n",
              " ('i hate pollution. i love the work of god. i', 0),\n",
              " ('i love the work of god. i love the beauty', 0),\n",
              " ('i love the beauty of this world. i adore the', 0),\n",
              " ('i adore the way people try solve hard things. i', 0),\n",
              " ('i am nothing but a blade of grass. i will', 0),\n",
              " ('i will unleash a lot of prophecies and will bring', 0),\n",
              " ('i love doing things in a peculiar way. i love', 0),\n",
              " ('i love and hate probability. it is so stupid and', 0),\n",
              " ('it is so stupid and fun at the same time.', 0),\n",
              " ('i love the way software programs work. i love my', 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2NyU5W4jA65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}